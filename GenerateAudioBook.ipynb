{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook expects the input manuscript in ./input/story.txt\n",
    "# and the voice model onnx files in ./PiperVoiceModels/ folder \n",
    "# and will output the audio files in ./output/\n",
    "\n",
    "# install the necessary packages \n",
    "# pip install crewai\n",
    "# pip install gTTS\n",
    "# pip install pydub\n",
    "# pip install ffmpegio\n",
    "\n",
    "# Import Necessary Libraries\n",
    "# This cell imports all required libraries for the workflow.\n",
    "\n",
    "# Downloaded ffmpeg as per this - https://stackoverflow.com/a/74658329/23656140\n",
    "\n",
    "# Piper TTS - https://github.com/rhasspy/piper\n",
    "# Piper downloaded from https://github.com/rhasspy/piper/releases\n",
    "# Voice models for Piper downloaded from https://rhasspy.github.io/piper-samples/\n",
    "# Use SSML Tags for better control over the voice - https://cloud.google.com/text-to-speech/docs/ssml\n",
    "\n",
    "import os\n",
    "from crewai import Agent, Task, Crew\n",
    "import subprocess\n",
    "from crewai import LLM\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "import pathlib\n",
    "\n",
    "import re\n",
    "from IPython.display import display, Audio\n",
    "\n",
    "ffmpeg_path = pathlib.Path.home() / 'AppData' / 'Local' / 'ffmpegio' / 'ffmpeg-downloader' / 'ffmpeg' / 'bin' \n",
    "AudioSegment.converter = ffmpeg_path / 'ffmpeg.exe'\n",
    "AudioSegment.ffmpeg = ffmpeg_path / 'ffmpeg.exe'\n",
    "AudioSegment.ffprobe = ffmpeg_path / 'ffprobe.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "os.environ['CREWAI_API_URL'] = 'http://localhost:11434'\n",
    "\n",
    "# Cell 2: Define the Local LLM with Ollama\n",
    "# This cell initializes the Ollama LLM (e.g., Llama 3) to be used by agents.\n",
    "\n",
    "llm = LLM(model=\"llama3.1:latest\", base_url=\"http://localhost:11434\", provider=\"ollama\", temperature=0.3, timeout=180000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Utility Functions\n",
    "# These functions handle manuscript splitting, TTS conversion, and audio merging.\n",
    "\n",
    "def read_manuscript(file_path):\n",
    "    \"\"\"Read the manuscript from a text file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Manuscript file '{file_path}' not found.\")\n",
    "        return None\n",
    "\n",
    "def split_manuscript(text, max_length=5000):\n",
    "    \"\"\"Split the manuscript into chunks based on natural breaks (paragraphs, chapters).\"\"\"\n",
    "    # Use regex to split on chapter headings or multiple newlines\n",
    "    sections = re.split(r'\\n{2,}|\\bChapter \\d+\\b', text)\n",
    "    chunks = []\n",
    "    current_chunk = \"\"\n",
    "    \n",
    "    for section in sections:\n",
    "        if len(current_chunk) + len(section) <= max_length:\n",
    "            current_chunk += section + \"\\n\\n\"\n",
    "        else:\n",
    "            if current_chunk:\n",
    "                chunks.append(current_chunk.strip())\n",
    "            current_chunk = section + \"\\n\\n\"\n",
    "    \n",
    "    if current_chunk:\n",
    "        chunks.append(current_chunk.strip())\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def text_to_speech(text, output_file, language='en', accent=None):\n",
    "    \"\"\"Convert text to speech using Piper TTS and save as an MP3 file.\"\"\"\n",
    "\n",
    "    piper_binary = r\"C:\\piperTTS\\piper.exe\"\n",
    "    \n",
    "    piper_model = r\"./PiperVoiceModels/en_GB-cori-high.onnx\"  # British Female\n",
    "    #piper_model = r\"./PiperVoiceModels/en_US-hfc_female-medium.onnx\"  # American Female\n",
    "\n",
    "    # Parameters for speed and pitch\n",
    "    length_scale = \"1.2\"  # Slow down by 20% (increase this value to slow down more)\n",
    "    f0_scale = \"0.8\"      # Increase pitch by 20% (increase this value to make pitch higher)\n",
    "\n",
    "    # Save as WAV\n",
    "    wav_file = output_file.replace('.mp3', '.wav')\n",
    "    piper_cmd = [\n",
    "        piper_binary,\n",
    "        \"--model\", piper_model,\n",
    "        \"--length_scale\", length_scale,     # adjust speed\n",
    "        \"--f0_scale\", f0_scale,             # adjust pitch\n",
    "        \"--sentence_silence\", \"0.5\",         # pause between sentences\n",
    "        \"--noise_scale\", \"0.0\",              # randomness and expressiveness in the voice\n",
    "        \"--output_file\", wav_file\n",
    "    ]\n",
    "\n",
    "    # Run Piper command with text piped in\n",
    "    try:\n",
    "        process = subprocess.Popen(piper_cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
    "        stdout, stderr = process.communicate(input=text)\n",
    "        if process.returncode != 0:\n",
    "            print(f\"Error running Piper TTS: {stderr}\")\n",
    "            return None\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error running Piper TTS: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Convert WAV to MP3\n",
    "    audio = AudioSegment.from_wav(wav_file)\n",
    "    audio.export(output_file, format=\"mp3\")\n",
    "\n",
    "    # Clean up the temporary WAV file\n",
    "    os.remove(wav_file)\n",
    "\n",
    "    return output_file\n",
    "\n",
    "def merge_audio_files(audio_files, output_file):\n",
    "    \"\"\"Merge multiple audio files into a single audiobook file.\"\"\"\n",
    "    combined = AudioSegment.empty()\n",
    "    for audio_file in audio_files:\n",
    "        if not os.path.exists(audio_file):\n",
    "           print(f\"Error: The file {audio_file} does not exist.\")\n",
    "           continue\n",
    "        print (\"*** Merging audio file \", audio_file)\n",
    "        audio = AudioSegment.from_mp3(audio_file)\n",
    "        combined += audio\n",
    "        # Delete the audio file after merging\n",
    "        os.remove(audio_file)\n",
    "        \n",
    "    combined.export(output_file, format=\"mp3\")\n",
    "    return output_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 4: Define CrewAI Agents\n",
    "# This cell defines the agents responsible for different tasks in the workflow.\n",
    "\n",
    "# Agent 1: Manuscript Splitter Agent\n",
    "splitter_agent = Agent(\n",
    "    role='Manuscript Splitter',\n",
    "    goal='Split the novel manuscript into manageable sections for narration',\n",
    "    backstory='You are an expert editor skilled at breaking down large texts into coherent, manageable sections while preserving narrative flow.',\n",
    "    verbose=True,\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "# Agent 2: Narration Agent\n",
    "narration_agent = Agent(\n",
    "    role='Narration Agent',\n",
    "    goal='Convert text sections into audio narration using text-to-speech',\n",
    "    backstory='You are a voice actor with expertise in converting written text into engaging audio narration, ensuring clarity and emotional tone.',\n",
    "    verbose=True,\n",
    "    llm=llm\n",
    ")\n",
    "\n",
    "# Agent 3: Audio Combiner Agent\n",
    "combiner_agent = Agent(\n",
    "    role='Audio Combiner',\n",
    "    goal='Combine individual audio files into a final audiobook file',\n",
    "    backstory='You are an audio engineer skilled at merging audio clips seamlessly to create a polished audiobook.',\n",
    "    verbose=True,\n",
    "    llm=llm\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 5: Define CrewAI Tasks\n",
    "# This cell defines the tasks each agent will perform.\n",
    "\n",
    "def create_split_task(manuscript_text):\n",
    "    return Task(\n",
    "        description=f'Split the following manuscript text into manageable sections for narration:\\n\\n{manuscript_text}',\n",
    "        agent=splitter_agent,\n",
    "        expected_output='A list of text sections, each no longer than 5000 characters, split at natural narrative breaks.'\n",
    "    )\n",
    "\n",
    "def create_narration_task(section, index):\n",
    "    return Task(\n",
    "        description=f'Convert the following text section into an audio file using text-to-speech:\\n\\n{section}',\n",
    "        agent=narration_agent,\n",
    "        expected_output=f'Audio file saved as section_{index}.mp3'\n",
    "    )\n",
    "\n",
    "def create_combiner_task(audio_files):\n",
    "    return Task(\n",
    "        description=f'Merge the following audio files into a single audiobook file: {audio_files}',\n",
    "        agent=combiner_agent,\n",
    "        expected_output='A single audiobook file named audiobook.mp3'\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell 6: Main Workflow Execution\n",
    "# This cell executes the entire workflow, from reading the manuscript to creating the audiobook.\n",
    "\n",
    "def main():\n",
    "    # Step 1: Read the manuscript\n",
    "    manuscript_path = \"./input/story.txt\"  # Replace with your manuscript file path\n",
    "    manuscript_text = read_manuscript(manuscript_path)\n",
    "    if not manuscript_text:\n",
    "        return\n",
    "\n",
    "    # Step 2: Split the manuscript into sections\n",
    "    print(\"Splitting manuscript into sections...\")\n",
    "    chunks = split_manuscript(manuscript_text)\n",
    "    print(f\"Manuscript split into {len(chunks)} sections.\")\n",
    "\n",
    "    # Step 3: Define tasks for splitting (though splitting is done programmatically here, we simulate agent involvement)\n",
    "    split_task = create_split_task(manuscript_text)\n",
    "\n",
    "    # Step 4: Convert each section to audio\n",
    "    audio_files = []\n",
    "    narration_tasks = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        output_file = f\"./output/section_{i}.mp3\"\n",
    "        print(f\"Converting section {i+1} to audio...\")\n",
    "        text_to_speech(chunk, output_file)\n",
    "        audio_files.append(output_file)\n",
    "        narration_tasks.append(create_narration_task(chunk, i))\n",
    "        \n",
    "    # Step 5: Merge audio files into a final audiobook\n",
    "    print(\"Merging audio files into final audiobook...\")\n",
    "    final_audiobook = \"./output/audiobook.mp3\"\n",
    "    merge_audio_files(audio_files, final_audiobook)\n",
    "\n",
    "    # Step 6: Define combiner task\n",
    "    combiner_task = create_combiner_task(audio_files)\n",
    "\n",
    "    # Step 7: Create and run the Crew\n",
    "    crew = Crew(\n",
    "        agents=[splitter_agent, narration_agent, combiner_agent],\n",
    "        tasks=[split_task] + narration_tasks + [combiner_task],\n",
    "        verbose=False  # Detailed logging\n",
    "    )\n",
    "\n",
    "    print(\"Starting CrewAI workflow...\")\n",
    "    crew.kickoff()\n",
    "\n",
    "    # Step 8: Display the final audiobook for playback in the notebook\n",
    "    print(f\"Audiobook created successfully: {final_audiobook}\")\n",
    "    display(Audio(final_audiobook))        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Run the Workflow\n",
    "# Execute the main function to start the workflow.\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
